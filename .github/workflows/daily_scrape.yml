name: Daily Zendesk Scraper

on:
  schedule:
    - cron: "0 1 * * *"
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - name: Prepare folders
        run: |
          mkdir -p logs
          mkdir -p state
          mkdir -p faiss_index

      - name: Restore state cache
        uses: actions/cache@v4
        with:
          path: state
          key: scraper-state
          restore-keys: scraper-state

      - name: Run scraper container
        run: |
          docker run \
          -e GROQ_API_KEY=${{ secrets.GROQ_API_KEY }} \
          -v ${{ github.workspace }}/state:/app/state \
          -v ${{ github.workspace }}/faiss_index:/app/faiss_index \
          -v ${{ github.workspace }}/logs:/app/logs \
          khangthinh/mynode-python-app

      - name: Save state cache
        uses: actions/cache@v4
        with:
          path: state
          key: scraper-state

      - name: Upload run log
        uses: actions/upload-artifact@v4
        with:
          name: run-log
          path: logs/last_run.json